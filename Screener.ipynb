{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwaRLKlcEAunoTPkBjGB1A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeilMitra/2WD-ObstacleAvoidingRobot/blob/master/Screener.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# üì¶ CELL 1 ‚Äì Install / upgrade required packages\n",
        "# =============================================================================\n",
        "!pip install --quiet yfinance statsmodels scikit-learn seaborn scipy\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# üìö CELL 2 ‚Äì Imports, global style, utilities\n",
        "# =============================================================================\n",
        "import os, warnings, pickle\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import coint\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "from scipy.stats import pearsonr, spearmanr                       # ‚Üê NEW\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use(\"seaborn-v0_8\")"
      ],
      "metadata": {
        "id": "YoD0TaC-Kfxa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ‚öôÔ∏è CELL 3 ‚Äì PairsTradingBacktester class\n",
        "# =============================================================================\n",
        "class PairsTradingBacktester:\n",
        "    \"\"\"\n",
        "    Machine-learning-augmented statistical-arbitrage back-tester\n",
        "    (cointegration + z-score + optional RandomForest filter)\n",
        "    \"\"\"\n",
        "\n",
        "    # ---------- init ----------\n",
        "    def __init__(\n",
        "        self,\n",
        "        symbols,\n",
        "        start_date,\n",
        "        end_date,\n",
        "        formation_period=252,\n",
        "        trading_period=63,\n",
        "        entry_threshold=2.0,\n",
        "        exit_threshold=0.5,\n",
        "        stop_loss_threshold=3.0,\n",
        "        transaction_cost=0.001,\n",
        "        use_ml=True,\n",
        "    ):\n",
        "        self.symbols = symbols\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.formation_period = formation_period\n",
        "        self.trading_period = trading_period\n",
        "        self.entry_threshold = entry_threshold\n",
        "        self.exit_threshold = exit_threshold\n",
        "        self.stop_loss_threshold = stop_loss_threshold\n",
        "        self.transaction_cost = transaction_cost\n",
        "        self.use_ml = use_ml\n",
        "        self.data = None\n",
        "        self.returns = None\n",
        "        self.pairs = []\n",
        "        self.portfolio_log = []           # ‚Üê start as list, convert to DF later\n",
        "\n",
        "    # ---------- data ----------\n",
        "    def download_data(self):\n",
        "        print(f\"Downloading {len(self.symbols)} tickers ‚Ä¶\")\n",
        "        try:\n",
        "            data = yf.download(self.symbols, start=self.start_date, end=self.end_date, progress=False)\n",
        "            if \"Adj Close\" in data.columns:\n",
        "                self.data = data[\"Adj Close\"]\n",
        "            elif \"Close\" in data.columns:\n",
        "                self.data = data[\"Close\"]\n",
        "            else:\n",
        "                print(\"No price column found!\"); return False\n",
        "\n",
        "            # Forward-fill gaps, drop columns (tickers) that are entirely NaN\n",
        "            self.data = self.data.ffill().dropna(axis=1, how=\"all\")\n",
        "            if self.data.empty:\n",
        "                print(\"No usable data downloaded.\"); return False\n",
        "\n",
        "            # Keep only symbols that survived cleaning\n",
        "            self.symbols = self.data.columns.tolist()\n",
        "            print(\"Data OK:\", self.data.shape)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(\"Download error:\", e)\n",
        "            return False\n",
        "\n",
        "    # ---------- pair search ----------\n",
        "    def find_cointegrated_pairs(self, data_period):\n",
        "        n = data_period.shape[1]\n",
        "        pairs, tested = [], set()\n",
        "        keys = data_period.columns\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                pair = tuple(sorted((keys[i], keys[j])))\n",
        "                if pair in tested: continue\n",
        "                tested.add(pair)\n",
        "\n",
        "                s1, s2 = np.log(data_period[pair[0]]), np.log(data_period[pair[1]])\n",
        "                if len(s1) < 20 or len(s2) < 20: continue\n",
        "                try:\n",
        "                    score, pval, _ = coint(s1, s2)\n",
        "                    if pval < 0.05: pairs.append((*pair, pval))\n",
        "                except: pass\n",
        "        pairs.sort(key=lambda x: x[2])\n",
        "        return [(p[0], p[1]) for p in pairs]\n",
        "\n",
        "    # ---------- feature engineering ----------\n",
        "    def calculate_spread_and_features(self, pair_data):\n",
        "        s1, s2 = pair_data.columns\n",
        "        spread = np.log(pair_data[s1]) - np.log(pair_data[s2])\n",
        "        mean = spread.rolling(window=self.formation_period // 4, min_periods=20).mean()\n",
        "        std = spread.rolling(window=self.formation_period // 4, min_periods=20).std()\n",
        "        z = (spread - mean) / std\n",
        "\n",
        "        feats = pd.DataFrame(index=pair_data.index)\n",
        "        feats[\"z_score\"] = z\n",
        "        feats[\"spread_volatility\"] = std\n",
        "        feats[\"pair_correlation\"] = (\n",
        "            pair_data[s1]\n",
        "            .rolling(self.formation_period // 4, min_periods=20)\n",
        "            .corr(pair_data[s2])\n",
        "        )\n",
        "        feats[\"spread_lag1\"] = spread.diff(1)\n",
        "        feats[\"spread_lag5\"] = spread.diff(5)\n",
        "\n",
        "        fwd_change = spread.shift(-5) - spread\n",
        "        feats[\"target\"] = np.where(\n",
        "            z > 0.5, (fwd_change < 0).astype(int),\n",
        "            np.where(z < -0.5, (fwd_change > 0).astype(int), 0)\n",
        "        )\n",
        "        feats.dropna(inplace=True)\n",
        "        return spread, z, feats\n",
        "\n",
        "    # ---------- ML ----------\n",
        "    def train_ml_model(self, feats):\n",
        "        if feats.empty or len(feats) < 50:\n",
        "            return None, None\n",
        "        X, y = feats.drop(\"target\", axis=1), feats[\"target\"]\n",
        "        scaler = StandardScaler().fit(X)\n",
        "        Xs = scaler.transform(X)\n",
        "        rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")\n",
        "        try:\n",
        "            rf.fit(Xs, y)\n",
        "            return rf, scaler\n",
        "        except ValueError as e:\n",
        "            print(\"RF fit error:\", e); return None, None\n",
        "\n",
        "    # ---------- back-test ----------\n",
        "    def run_backtest(self):\n",
        "        if not self.download_data(): return None\n",
        "        all_rets = pd.Series(0.0, index=self.data.index)\n",
        "\n",
        "        for t in range(self.formation_period,\n",
        "                       len(self.data) - self.trading_period,\n",
        "                       self.trading_period):\n",
        "\n",
        "            f_start, f_end = self.data.index[t - self.formation_period], self.data.index[t - 1]\n",
        "            tr_start, tr_end = self.data.index[t], self.data.index[t + self.trading_period - 1]\n",
        "            print(f\"\\nWindow  {f_start.date()} ‚Üí {f_end.date()}  |  trade {tr_start.date()} ‚Üí {tr_end.date()}\")\n",
        "\n",
        "            f_data = self.data.loc[f_start:f_end]\n",
        "            tr_data = self.data.loc[tr_start:tr_end]\n",
        "            current_pairs = self.find_cointegrated_pairs(f_data)\n",
        "            if not current_pairs: continue\n",
        "\n",
        "            period_rets = pd.Series(0.0, index=tr_data.index)\n",
        "            active_pairs = 0\n",
        "\n",
        "            for pair in current_pairs:\n",
        "                s1, s2 = pair; key = tuple(sorted(pair))\n",
        "                combo = self.data.loc[f_start:tr_end, [s1, s2]]\n",
        "                if combo.isnull().values.any() or len(combo) < self.formation_period: continue\n",
        "\n",
        "                spread, z, feats = self.calculate_spread_and_features(combo)\n",
        "\n",
        "                z_tr = z.reindex(tr_data.index).ffill()\n",
        "                feats_tr = feats.reindex(tr_data.index).ffill()\n",
        "\n",
        "                ml, scaler = (None, None)\n",
        "                if self.use_ml:\n",
        "                    ml, scaler = self.train_ml_model(feats.loc[:f_end])\n",
        "\n",
        "                pos = 0\n",
        "                daily_pnl = pd.Series(0.0, index=tr_data.index)\n",
        "\n",
        "                for i, date in enumerate(tr_data.index):\n",
        "                    if pd.isna(z_tr[date]): continue\n",
        "                    z_now = z_tr[date]; ml_pred = 1\n",
        "                    if self.use_ml and ml is not None and date in feats_tr.index:\n",
        "                        feat = feats_tr.loc[[date]].drop(\"target\", axis=1, errors=\"ignore\")\n",
        "                        if not feat.isnull().values.any():\n",
        "                            ml_pred = ml.predict(scaler.transform(feat))[0]\n",
        "                        else:\n",
        "                            ml_pred = 0\n",
        "\n",
        "                    # ----- entry -----\n",
        "                    if pos == 0:\n",
        "                        if z_now < -self.entry_threshold and ml_pred == 1:\n",
        "                            pos = 1\n",
        "                            daily_pnl[date] -= self.transaction_cost * 2\n",
        "                            self.portfolio_log.append(\n",
        "                                dict(Date=date, Pair=key, Action=\"Enter Long\", Z=z_now, ML=ml_pred)\n",
        "                            )\n",
        "                        elif z_now > self.entry_threshold and ml_pred == 1:\n",
        "                            pos = -1\n",
        "                            daily_pnl[date] -= self.transaction_cost * 2\n",
        "                            self.portfolio_log.append(\n",
        "                                dict(Date=date, Pair=key, Action=\"Enter Short\", Z=z_now, ML=ml_pred)\n",
        "                            )\n",
        "\n",
        "                    # ----- manage / exit -----\n",
        "                    else:\n",
        "                        p_s1, p_s2 = tr_data.loc[date, s1], tr_data.loc[date, s2]\n",
        "                        if i > 0:\n",
        "                            prev = tr_data.index[i - 1]\n",
        "                            ret = pos * (\n",
        "                                (p_s1 / tr_data.loc[prev, s1] - 1) -\n",
        "                                (p_s2 / tr_data.loc[prev, s2] - 1)\n",
        "                            ) / 2.0\n",
        "                            daily_pnl[date] += ret\n",
        "\n",
        "                        exit_sig, reason = False, \"\"\n",
        "                        if pos == 1 and z_now >= -self.exit_threshold:\n",
        "                            exit_sig, reason = True, \"Exit Long\"\n",
        "                        elif pos == -1 and z_now <= self.exit_threshold:\n",
        "                            exit_sig, reason = True, \"Exit Short\"\n",
        "                        elif pos == 1 and z_now < -self.stop_loss_threshold:\n",
        "                            exit_sig, reason = True, \"Stop-loss Long\"\n",
        "                        elif pos == -1 and z_now > self.stop_loss_threshold:\n",
        "                            exit_sig, reason = True, \"Stop-loss Short\"\n",
        "                        elif date == tr_data.index[-1]:\n",
        "                            exit_sig, reason = True, \"End of period\"\n",
        "\n",
        "                        if exit_sig:\n",
        "                            daily_pnl[date] -= self.transaction_cost * 2\n",
        "                            self.portfolio_log.append(\n",
        "                                dict(Date=date, Pair=key, Action=reason, Z=z_now, PnL=daily_pnl[date])\n",
        "                            )\n",
        "                            pos = 0\n",
        "\n",
        "                if not daily_pnl.eq(0).all():\n",
        "                    period_rets = period_rets.add(daily_pnl, fill_value=0)\n",
        "                    active_pairs += 1\n",
        "\n",
        "            if active_pairs:\n",
        "                all_rets.loc[tr_start:tr_end] = all_rets.loc[tr_start:tr_end].add(\n",
        "                    period_rets / active_pairs, fill_value=0\n",
        "                )\n",
        "            print(\"Active pairs:\", active_pairs)\n",
        "\n",
        "        self.returns = all_rets.loc[self.data.index[self.formation_period]:]\n",
        "        self.portfolio_log = pd.DataFrame(self.portfolio_log)\n",
        "        print(\"Back-test complete.\")\n",
        "        return self.returns\n",
        "\n",
        "    # ---------- simple plots & metrics ----------\n",
        "    def plot_performance(self, rets, title=\"Cumulative Returns\", fname=None):\n",
        "        if rets is None or rets.empty: return\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        ((1 + rets).cumprod() - 1).plot()\n",
        "        plt.title(title); plt.ylabel(\"Cumulative return\"); plt.grid(True)\n",
        "        if fname: plt.savefig(fname); plt.close()\n",
        "\n",
        "    def calculate_performance_metrics(self, rets):\n",
        "        if rets is None or rets.empty: return {}\n",
        "        cum_ret = (1 + rets).prod() - 1\n",
        "        ann_ret = (1 + rets.mean()) ** 252 - 1\n",
        "        ann_vol = rets.std() * np.sqrt(252)\n",
        "        sharpe = ann_ret / ann_vol if ann_vol else 0\n",
        "        draw = (1 + rets).cumprod()\n",
        "        max_dd = (draw / draw.cummax() - 1).min()\n",
        "        neg = rets[rets < 0]\n",
        "        sortino = ann_ret / (neg.std() * np.sqrt(252)) if len(neg) else 0\n",
        "        print(f\"Sharpe {sharpe:.2f} | Sortino {sortino:.2f} | Max-DD {max_dd:.2%}\")\n",
        "        return dict(CumRet=cum_ret, AnnRet=ann_ret, AnnVol=ann_vol,\n",
        "                    Sharpe=sharpe, Sortino=sortino, MaxDD=max_dd)"
      ],
      "metadata": {
        "id": "Dqkq0kQZeXyr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQLLH_iXee-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}