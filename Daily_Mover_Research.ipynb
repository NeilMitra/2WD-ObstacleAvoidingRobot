{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeilMitra/2WD-ObstacleAvoidingRobot/blob/master/Daily_Mover_Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm"
      ],
      "metadata": {
        "id": "WKqu5vJ_o2W7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fe4adjxVovxd"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOCtjmbSvEzo",
        "outputId": "ac1b8c29-d395-41f0-ae6f-0e444851747d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for MMM...\n",
            "Downloading data for AOS...\n",
            "Downloading data for ABT...\n",
            "Downloading data for ABBV...\n",
            "Downloading data for ACN...\n",
            "Downloading data for ADBE...\n",
            "Downloading data for AMD...\n",
            "Downloading data for AES...\n",
            "Downloading data for AFL...\n",
            "Downloading data for A...\n",
            "Downloading data for APD...\n",
            "Downloading data for ABNB...\n",
            "Downloading data for AKAM...\n",
            "Downloading data for ALB...\n",
            "Downloading data for ARE...\n",
            "Downloading data for ALGN...\n",
            "Downloading data for ALLE...\n",
            "Downloading data for LNT...\n",
            "Downloading data for ALL...\n",
            "Downloading data for GOOGL...\n",
            "Downloading data for GOOG...\n",
            "Downloading data for MO...\n",
            "Downloading data for AMZN...\n",
            "Downloading data for AMCR...\n",
            "Downloading data for AEE...\n",
            "Downloading data for AEP...\n",
            "Downloading data for AXP...\n",
            "Downloading data for AIG...\n",
            "Downloading data for AMT...\n",
            "Downloading data for AWK...\n",
            "Downloading data for AMP...\n",
            "Downloading data for AME...\n",
            "Downloading data for AMGN...\n",
            "Downloading data for APH...\n",
            "Downloading data for ADI...\n",
            "Downloading data for ANSS...\n",
            "Downloading data for AON...\n",
            "Downloading data for APA...\n",
            "Downloading data for APO...\n",
            "Downloading data for AAPL...\n",
            "Downloading data for AMAT...\n",
            "Downloading data for APTV...\n",
            "Downloading data for ACGL...\n",
            "Downloading data for ADM...\n",
            "Downloading data for ANET...\n",
            "Downloading data for AJG...\n",
            "Downloading data for AIZ...\n",
            "Downloading data for T...\n",
            "Downloading data for ATO...\n",
            "Downloading data for ADSK...\n",
            "Downloading data for ADP...\n",
            "Downloading data for AZO...\n",
            "Downloading data for AVB...\n",
            "Downloading data for AVY...\n",
            "Downloading data for AXON...\n",
            "Downloading data for BKR...\n",
            "Downloading data for BALL...\n",
            "Downloading data for BAC...\n",
            "Downloading data for BAX...\n",
            "Downloading data for BDX...\n",
            "Downloading data for BRK.B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for BRK.B. Skipping.\n",
            "Downloading data for BBY...\n",
            "Downloading data for TECH...\n",
            "Downloading data for BIIB...\n",
            "Downloading data for BLK...\n",
            "Downloading data for BX...\n",
            "Downloading data for BK...\n",
            "Downloading data for BA...\n",
            "Downloading data for BKNG...\n",
            "Downloading data for BSX...\n",
            "Downloading data for BMY...\n",
            "Downloading data for AVGO...\n",
            "Downloading data for BR...\n",
            "Downloading data for BRO...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2023-12-31)')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for BF.B...\n",
            "No data for BF.B. Skipping.\n",
            "Downloading data for BLDR...\n",
            "Downloading data for BG...\n",
            "Downloading data for BXP...\n",
            "Downloading data for CHRW...\n",
            "Downloading data for CDNS...\n",
            "Downloading data for CZR...\n",
            "Downloading data for CPT...\n",
            "Downloading data for CPB...\n",
            "Downloading data for COF...\n",
            "Downloading data for CAH...\n",
            "Downloading data for KMX...\n",
            "Downloading data for CCL...\n",
            "Downloading data for CARR...\n",
            "Downloading data for CAT...\n",
            "Downloading data for CBOE...\n",
            "Downloading data for CBRE...\n",
            "Downloading data for CDW...\n",
            "Downloading data for COR...\n",
            "Downloading data for CNC...\n",
            "Downloading data for CNP...\n",
            "Downloading data for CF...\n",
            "Downloading data for CRL...\n",
            "Downloading data for SCHW...\n",
            "Downloading data for CHTR...\n",
            "Downloading data for CVX...\n",
            "Downloading data for CMG...\n",
            "Downloading data for CB...\n",
            "Downloading data for CHD...\n",
            "Downloading data for CI...\n",
            "Downloading data for CINF...\n",
            "Downloading data for CTAS...\n",
            "Downloading data for CSCO...\n",
            "Downloading data for C...\n",
            "Downloading data for CFG...\n",
            "Downloading data for CLX...\n",
            "Downloading data for CME...\n",
            "Downloading data for CMS...\n",
            "Downloading data for KO...\n",
            "Downloading data for CTSH...\n",
            "Downloading data for CL...\n",
            "Downloading data for CMCSA...\n",
            "Downloading data for CAG...\n",
            "Downloading data for COP...\n",
            "Downloading data for ED...\n",
            "Downloading data for STZ...\n",
            "Downloading data for CEG...\n",
            "Downloading data for COO...\n",
            "Downloading data for CPRT...\n",
            "Downloading data for GLW...\n",
            "Downloading data for CPAY...\n",
            "Downloading data for CTVA...\n",
            "Downloading data for CSGP...\n",
            "Downloading data for COST...\n",
            "Downloading data for CTRA...\n",
            "Downloading data for CRWD...\n",
            "Downloading data for CCI...\n",
            "Downloading data for CSX...\n",
            "Downloading data for CMI...\n",
            "Downloading data for CVS...\n",
            "Downloading data for DHR...\n",
            "Downloading data for DRI...\n",
            "Downloading data for DVA...\n",
            "Downloading data for DAY...\n",
            "Downloading data for DECK...\n",
            "Downloading data for DE...\n",
            "Downloading data for DELL...\n",
            "Downloading data for DAL...\n",
            "Downloading data for DVN...\n",
            "Downloading data for DXCM...\n",
            "Downloading data for FANG...\n",
            "Downloading data for DLR...\n",
            "Downloading data for DFS...\n",
            "Downloading data for DG...\n",
            "Downloading data for DLTR...\n",
            "Downloading data for D...\n",
            "Downloading data for DPZ...\n",
            "Downloading data for DASH...\n",
            "Downloading data for DOV...\n",
            "Downloading data for DOW...\n",
            "Downloading data for DHI...\n",
            "Downloading data for DTE...\n",
            "Downloading data for DUK...\n",
            "Downloading data for DD...\n",
            "Downloading data for EMN...\n",
            "Downloading data for ETN...\n",
            "Downloading data for EBAY...\n",
            "Downloading data for ECL...\n",
            "Downloading data for EIX...\n",
            "Downloading data for EW...\n",
            "Downloading data for EA...\n",
            "Downloading data for ELV...\n",
            "Downloading data for EMR...\n",
            "Downloading data for ENPH...\n",
            "Downloading data for ETR...\n",
            "Downloading data for EOG...\n",
            "Downloading data for EPAM...\n",
            "Downloading data for EQT...\n",
            "Downloading data for EFX...\n",
            "Downloading data for EQIX...\n",
            "Downloading data for EQR...\n",
            "Downloading data for ERIE...\n",
            "Downloading data for ESS...\n",
            "Downloading data for EL...\n",
            "Downloading data for EG...\n",
            "Downloading data for EVRG...\n",
            "Downloading data for ES...\n",
            "Downloading data for EXC...\n",
            "Downloading data for EXE...\n",
            "Downloading data for EXPE...\n",
            "Downloading data for EXPD...\n",
            "Downloading data for EXR...\n",
            "Downloading data for XOM...\n",
            "Downloading data for FFIV...\n",
            "Downloading data for FDS...\n",
            "Downloading data for FICO...\n",
            "Downloading data for FAST...\n",
            "Downloading data for FRT...\n",
            "Downloading data for FDX...\n",
            "Downloading data for FIS...\n",
            "Downloading data for FITB...\n",
            "Downloading data for FSLR...\n",
            "Downloading data for FE...\n",
            "Downloading data for FI...\n",
            "Downloading data for F...\n",
            "Downloading data for FTNT...\n",
            "Downloading data for FTV...\n",
            "Downloading data for FOXA...\n",
            "Downloading data for FOX...\n",
            "Downloading data for BEN...\n",
            "Downloading data for FCX...\n",
            "Downloading data for GRMN...\n",
            "Downloading data for IT...\n",
            "Downloading data for GE...\n",
            "Downloading data for GEHC...\n",
            "Downloading data for GEV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['GEV']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2023-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1356930000, endDate = 1703998800\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for GEV. Skipping.\n",
            "Downloading data for GEN...\n",
            "Downloading data for GNRC...\n",
            "Downloading data for GD...\n",
            "Downloading data for GIS...\n",
            "Downloading data for GM...\n",
            "Downloading data for GPC...\n",
            "Downloading data for GILD...\n",
            "Downloading data for GPN...\n",
            "Downloading data for GL...\n",
            "Downloading data for GDDY...\n",
            "Downloading data for GS...\n",
            "Downloading data for HAL...\n",
            "Downloading data for HIG...\n",
            "Downloading data for HAS...\n",
            "Downloading data for HCA...\n",
            "Downloading data for DOC...\n",
            "Downloading data for HSIC...\n",
            "Downloading data for HSY...\n",
            "Downloading data for HES...\n",
            "Downloading data for HPE...\n",
            "Downloading data for HLT...\n",
            "Downloading data for HOLX...\n",
            "Downloading data for HD...\n",
            "Downloading data for HON...\n",
            "Downloading data for HRL...\n",
            "Downloading data for HST...\n",
            "Downloading data for HWM...\n",
            "Downloading data for HPQ...\n",
            "Downloading data for HUBB...\n",
            "Downloading data for HUM...\n",
            "Downloading data for HBAN...\n",
            "Downloading data for HII...\n",
            "Downloading data for IBM...\n",
            "Downloading data for IEX...\n",
            "Downloading data for IDXX...\n",
            "Downloading data for ITW...\n",
            "Downloading data for INCY...\n",
            "Downloading data for IR...\n",
            "Downloading data for PODD...\n",
            "Downloading data for INTC...\n",
            "Downloading data for ICE...\n",
            "Downloading data for IFF...\n",
            "Downloading data for IP...\n",
            "Downloading data for IPG...\n",
            "Downloading data for INTU...\n",
            "Downloading data for ISRG...\n",
            "Downloading data for IVZ...\n",
            "Downloading data for INVH...\n",
            "Downloading data for IQV...\n",
            "Downloading data for IRM...\n",
            "Downloading data for JBHT...\n",
            "Downloading data for JBL...\n",
            "Downloading data for JKHY...\n",
            "Downloading data for J...\n",
            "Downloading data for JNJ...\n",
            "Downloading data for JCI...\n",
            "Downloading data for JPM...\n",
            "Downloading data for JNPR...\n",
            "Downloading data for K...\n",
            "Downloading data for KVUE...\n",
            "Downloading data for KDP...\n",
            "Downloading data for KEY...\n",
            "Downloading data for KEYS...\n",
            "Downloading data for KMB...\n",
            "Downloading data for KIM...\n",
            "Downloading data for KMI...\n",
            "Downloading data for KKR...\n",
            "Downloading data for KLAC...\n",
            "Downloading data for KHC...\n",
            "Downloading data for KR...\n",
            "Downloading data for LHX...\n",
            "Downloading data for LH...\n",
            "Downloading data for LRCX...\n",
            "Downloading data for LW...\n",
            "Downloading data for LVS...\n",
            "Downloading data for LDOS...\n",
            "Downloading data for LEN...\n",
            "Downloading data for LII...\n",
            "Downloading data for LLY...\n",
            "Downloading data for LIN...\n",
            "Downloading data for LYV...\n",
            "Downloading data for LKQ...\n",
            "Downloading data for LMT...\n",
            "Downloading data for L...\n",
            "Downloading data for LOW...\n",
            "Downloading data for LULU...\n",
            "Downloading data for LYB...\n",
            "Downloading data for MTB...\n",
            "Downloading data for MPC...\n",
            "Downloading data for MKTX...\n",
            "Downloading data for MAR...\n",
            "Downloading data for MMC...\n",
            "Downloading data for MLM...\n",
            "Downloading data for MAS...\n",
            "Downloading data for MA...\n",
            "Downloading data for MTCH...\n",
            "Downloading data for MKC...\n",
            "Downloading data for MCD...\n",
            "Downloading data for MCK...\n",
            "Downloading data for MDT...\n",
            "Downloading data for MRK...\n",
            "Downloading data for META...\n",
            "Downloading data for MET...\n",
            "Downloading data for MTD...\n",
            "Downloading data for MGM...\n",
            "Downloading data for MCHP...\n",
            "Downloading data for MU...\n",
            "Downloading data for MSFT...\n",
            "Downloading data for MAA...\n",
            "Downloading data for MRNA...\n",
            "Downloading data for MHK...\n",
            "Downloading data for MOH...\n",
            "Downloading data for TAP...\n",
            "Downloading data for MDLZ...\n",
            "Downloading data for MPWR...\n",
            "Downloading data for MNST...\n",
            "Downloading data for MCO...\n",
            "Downloading data for MS...\n",
            "Downloading data for MOS...\n",
            "Downloading data for MSI...\n",
            "Downloading data for MSCI...\n",
            "Downloading data for NDAQ...\n",
            "Downloading data for NTAP...\n",
            "Downloading data for NFLX...\n",
            "Downloading data for NEM...\n",
            "Downloading data for NWSA...\n",
            "Downloading data for NWS...\n",
            "Downloading data for NEE...\n",
            "Downloading data for NKE...\n",
            "Downloading data for NI...\n",
            "Downloading data for NDSN...\n",
            "Downloading data for NSC...\n",
            "Downloading data for NTRS...\n",
            "Downloading data for NOC...\n",
            "Downloading data for NCLH...\n",
            "Downloading data for NRG...\n",
            "Downloading data for NUE...\n",
            "Downloading data for NVDA...\n",
            "Downloading data for NVR...\n",
            "Downloading data for NXPI...\n",
            "Downloading data for ORLY...\n",
            "Downloading data for OXY...\n",
            "Downloading data for ODFL...\n",
            "Downloading data for OMC...\n",
            "Downloading data for ON...\n",
            "Downloading data for OKE...\n",
            "Downloading data for ORCL...\n",
            "Downloading data for OTIS...\n",
            "Downloading data for PCAR...\n",
            "Downloading data for PKG...\n",
            "Downloading data for PLTR...\n",
            "Downloading data for PANW...\n",
            "Downloading data for PARA...\n",
            "Downloading data for PH...\n",
            "Downloading data for PAYX...\n",
            "Downloading data for PAYC...\n",
            "Downloading data for PYPL...\n",
            "Downloading data for PNR...\n",
            "Downloading data for PEP...\n",
            "Downloading data for PFE...\n",
            "Downloading data for PCG...\n",
            "Downloading data for PM...\n",
            "Downloading data for PSX...\n",
            "Downloading data for PNW...\n",
            "Downloading data for PNC...\n",
            "Downloading data for POOL...\n",
            "Downloading data for PPG...\n",
            "Downloading data for PPL...\n",
            "Downloading data for PFG...\n",
            "Downloading data for PG...\n",
            "Downloading data for PGR...\n",
            "Downloading data for PLD...\n",
            "Downloading data for PRU...\n",
            "Downloading data for PEG...\n",
            "Downloading data for PTC...\n",
            "Downloading data for PSA...\n",
            "Downloading data for PHM...\n",
            "Downloading data for PWR...\n",
            "Downloading data for QCOM...\n",
            "Downloading data for DGX...\n",
            "Downloading data for RL...\n",
            "Downloading data for RJF...\n",
            "Downloading data for RTX...\n",
            "Downloading data for O...\n",
            "Downloading data for REG...\n",
            "Downloading data for REGN...\n",
            "Downloading data for RF...\n",
            "Downloading data for RSG...\n",
            "Downloading data for RMD...\n",
            "Downloading data for RVTY...\n",
            "Downloading data for ROK...\n",
            "Downloading data for ROL...\n",
            "Downloading data for ROP...\n",
            "Downloading data for ROST...\n",
            "Downloading data for RCL...\n",
            "Downloading data for SPGI...\n",
            "Downloading data for CRM...\n",
            "Downloading data for SBAC...\n",
            "Downloading data for SLB...\n",
            "Downloading data for STX...\n",
            "Downloading data for SRE...\n",
            "Downloading data for NOW...\n",
            "Downloading data for SHW...\n",
            "Downloading data for SPG...\n",
            "Downloading data for SWKS...\n",
            "Downloading data for SJM...\n",
            "Downloading data for SW...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SW']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2023-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1356930000, endDate = 1703998800\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for SW. Skipping.\n",
            "Downloading data for SNA...\n",
            "Downloading data for SOLV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SOLV']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2023-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1356930000, endDate = 1703998800\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for SOLV. Skipping.\n",
            "Downloading data for SO...\n",
            "Downloading data for LUV...\n",
            "Downloading data for SWK...\n",
            "Downloading data for SBUX...\n",
            "Downloading data for STT...\n",
            "Downloading data for STLD...\n",
            "Downloading data for STE...\n",
            "Downloading data for SYK...\n",
            "Downloading data for SMCI...\n",
            "Downloading data for SYF...\n",
            "Downloading data for SNPS...\n",
            "Downloading data for SYY...\n",
            "Downloading data for TMUS...\n",
            "Downloading data for TROW...\n",
            "Downloading data for TTWO...\n",
            "Downloading data for TPR...\n",
            "Downloading data for TRGP...\n",
            "Downloading data for TGT...\n",
            "Downloading data for TEL...\n",
            "Downloading data for TDY...\n",
            "Downloading data for TER...\n",
            "Downloading data for TSLA...\n",
            "Downloading data for TXN...\n",
            "Downloading data for TPL...\n",
            "Downloading data for TXT...\n",
            "Downloading data for TMO...\n",
            "Downloading data for TJX...\n",
            "Downloading data for TKO...\n",
            "Downloading data for TSCO...\n",
            "Downloading data for TT...\n",
            "Downloading data for TDG...\n",
            "Downloading data for TRV...\n",
            "Downloading data for TRMB...\n",
            "Downloading data for TFC...\n",
            "Downloading data for TYL...\n",
            "Downloading data for TSN...\n",
            "Downloading data for USB...\n",
            "Downloading data for UBER...\n",
            "Downloading data for UDR...\n",
            "Downloading data for ULTA...\n",
            "Downloading data for UNP...\n",
            "Downloading data for UAL...\n",
            "Downloading data for UPS...\n",
            "Downloading data for URI...\n",
            "Downloading data for UNH...\n",
            "Downloading data for UHS...\n",
            "Downloading data for VLO...\n",
            "Downloading data for VTR...\n",
            "Downloading data for VLTO...\n",
            "Downloading data for VRSN...\n",
            "Downloading data for VRSK...\n",
            "Downloading data for VZ...\n",
            "Downloading data for VRTX...\n",
            "Downloading data for VTRS...\n",
            "Downloading data for VICI...\n",
            "Downloading data for V...\n",
            "Downloading data for VST...\n",
            "Downloading data for VMC...\n",
            "Downloading data for WRB...\n",
            "Downloading data for GWW...\n",
            "Downloading data for WAB...\n",
            "Downloading data for WBA...\n",
            "Downloading data for WMT...\n",
            "Downloading data for DIS...\n",
            "Downloading data for WBD...\n",
            "Downloading data for WM...\n",
            "Downloading data for WAT...\n",
            "Downloading data for WEC...\n",
            "Downloading data for WFC...\n",
            "Downloading data for WELL...\n",
            "Downloading data for WST...\n",
            "Downloading data for WDC...\n",
            "Downloading data for WY...\n",
            "Downloading data for WSM...\n",
            "Downloading data for WMB...\n",
            "Downloading data for WTW...\n",
            "Downloading data for WDAY...\n",
            "Downloading data for WYNN...\n",
            "Downloading data for XEL...\n",
            "Downloading data for XYL...\n",
            "Downloading data for YUM...\n",
            "Downloading data for ZBRA...\n",
            "Downloading data for ZBH...\n",
            "Downloading data for ZTS...\n",
            "\n",
            "\n",
            "==================== FINAL RESULTS ====================\n",
            "01/03:\n",
            "  Consistently DOWN: ['ES']\n",
            "---------------------------------------------------\n",
            "01/05:\n",
            "  Consistently DOWN: ['XYL']\n",
            "---------------------------------------------------\n",
            "01/06:\n",
            "  Consistently UP:   ['REG']\n",
            "---------------------------------------------------\n",
            "01/08:\n",
            "  Consistently UP:   ['RMD']\n",
            "---------------------------------------------------\n",
            "01/11:\n",
            "  Consistently UP:   ['ON']\n",
            "---------------------------------------------------\n",
            "01/13:\n",
            "  Consistently DOWN: ['DLTR', 'HD', 'SLB']\n",
            "---------------------------------------------------\n",
            "01/18:\n",
            "  Consistently UP:   ['LII']\n",
            "---------------------------------------------------\n",
            "01/22:\n",
            "  Consistently UP:   ['FITB']\n",
            "---------------------------------------------------\n",
            "01/23:\n",
            "  Consistently DOWN: ['SCHW', 'F', 'MS', 'PRU']\n",
            "---------------------------------------------------\n",
            "01/27:\n",
            "  Consistently DOWN: ['AFL', 'APD', 'GOOGL', 'GOOG', 'AXP', 'AME', 'CINF', 'CTAS', 'CMI', 'DVA', 'GM', 'GL', 'HD', 'MET', 'PRU', 'UHS']\n",
            "---------------------------------------------------\n",
            "01/31:\n",
            "  Consistently UP:   ['AEE', 'AEP', 'CMS']\n",
            "---------------------------------------------------\n",
            "02/04:\n",
            "  Consistently DOWN: ['FE']\n",
            "---------------------------------------------------\n",
            "02/06:\n",
            "  Consistently UP:   ['LMT']\n",
            "---------------------------------------------------\n",
            "02/09:\n",
            "  Consistently UP:   ['O']\n",
            "---------------------------------------------------\n",
            "02/10:\n",
            "  Consistently UP:   ['CVS']\n",
            "---------------------------------------------------\n",
            "02/12:\n",
            "  Consistently UP:   ['ADBE', 'ADI', 'APTV', 'BR', 'DOV', 'ETN', 'IEX', 'ITW', 'NSC', 'PH', 'ROK', 'SWK', 'TEL', 'UNP', 'URI', 'XYL']\n",
            "---------------------------------------------------\n",
            "02/13:\n",
            "  Consistently UP:   ['FI', 'IPG', 'LKQ', 'TKO', 'URI']\n",
            "---------------------------------------------------\n",
            "02/14:\n",
            "  Consistently UP:   ['NVDA']\n",
            "---------------------------------------------------\n",
            "02/15:\n",
            "  Consistently UP:   ['BIIB', 'CTAS', 'LKQ', 'MMC', 'MA']\n",
            "---------------------------------------------------\n",
            "02/16:\n",
            "  Consistently UP:   ['ATO', 'HES', 'MMC']\n",
            "---------------------------------------------------\n",
            "02/17:\n",
            "  Consistently UP:   ['AIG']\n",
            "---------------------------------------------------\n",
            "03/01:\n",
            "  Consistently UP:   ['LDOS']\n",
            "---------------------------------------------------\n",
            "03/02:\n",
            "  Consistently UP:   ['WELL']\n",
            "---------------------------------------------------\n",
            "03/03:\n",
            "  Consistently DOWN: ['LULU', 'MAR', 'NKE']\n",
            "---------------------------------------------------\n",
            "03/04:\n",
            "  Consistently UP:   ['CMS']\n",
            "---------------------------------------------------\n",
            "03/06:\n",
            "  Consistently DOWN: ['MNST']\n",
            "---------------------------------------------------\n",
            "03/07:\n",
            "  Consistently DOWN: ['NFLX']\n",
            "---------------------------------------------------\n",
            "03/08:\n",
            "  Consistently DOWN: ['FFIV', 'OKE']\n",
            "---------------------------------------------------\n",
            "03/10:\n",
            "  Consistently UP:   ['DTE', 'EXC']\n",
            "---------------------------------------------------\n",
            "03/18:\n",
            "  Consistently DOWN: ['CBOE']\n",
            "---------------------------------------------------\n",
            "03/19:\n",
            "  Consistently DOWN: ['AVB', 'NTAP', 'PFG', 'REG', 'TROW', 'UDR']\n",
            "---------------------------------------------------\n",
            "03/22:\n",
            "  Consistently DOWN: ['CF']\n",
            "---------------------------------------------------\n",
            "03/23:\n",
            "  Consistently DOWN: ['MMM', 'APH', 'APO', 'ADP', 'BX', 'DHR', 'HSIC', 'HUM', 'IFF', 'ROK', 'TEL', 'TXT', 'WBA', 'XYL']\n",
            "---------------------------------------------------\n",
            "03/24:\n",
            "  Consistently UP:   ['APA']\n",
            "---------------------------------------------------\n",
            "03/26:\n",
            "  Consistently UP:   ['EPAM', 'ISRG']\n",
            "---------------------------------------------------\n",
            "03/27:\n",
            "  Consistently DOWN: ['BAC', 'CVX', 'FITB', 'KEY']\n",
            "---------------------------------------------------\n",
            "03/28:\n",
            "  Consistently UP:   ['ARE', 'BRO', 'COR', 'CLX', 'DPZ', 'ECL', 'EQIX', 'HSY', 'KMB', 'SJM', 'UNH', 'WBA', 'WSM', 'YUM']\n",
            "---------------------------------------------------\n",
            "03/29:\n",
            "  Consistently UP:   ['DTE', 'MDLZ', 'PPG', 'REGN', 'VRSN']\n",
            "---------------------------------------------------\n",
            "03/31:\n",
            "  Consistently DOWN: ['CLX']\n",
            "---------------------------------------------------\n",
            "04/04:\n",
            "  Consistently UP:   ['CLX']\n",
            "---------------------------------------------------\n",
            "04/07:\n",
            "  Consistently DOWN: ['UPS']\n",
            "---------------------------------------------------\n",
            "04/08:\n",
            "  Consistently UP:   ['CPRT', 'CPAY']\n",
            "---------------------------------------------------\n",
            "04/11:\n",
            "  Consistently DOWN: ['PARA', 'TXN', 'WM']\n",
            "---------------------------------------------------\n",
            "04/16:\n",
            "  Consistently UP:   ['GOOG', 'AMZN', 'EMN', 'EBAY', 'LDOS', 'ODFL', 'SNA', 'TROW']\n",
            "---------------------------------------------------\n",
            "04/23:\n",
            "  Consistently UP:   ['GEN', 'GPC', 'JNJ', 'MAR', 'MOH', 'ORLY']\n",
            "---------------------------------------------------\n",
            "04/24:\n",
            "  Consistently UP:   ['TXN']\n",
            "  Consistently DOWN: ['AMT']\n",
            "---------------------------------------------------\n",
            "04/27:\n",
            "  Consistently UP:   ['AIG']\n",
            "---------------------------------------------------\n",
            "05/02:\n",
            "  Consistently UP:   ['BBY', 'HD', 'ISRG', 'LOW', 'MLM', 'ORLY', 'TSCO', 'WSM']\n",
            "---------------------------------------------------\n",
            "05/04:\n",
            "  Consistently UP:   ['BALL']\n",
            "---------------------------------------------------\n",
            "05/06:\n",
            "  Consistently DOWN: ['PCG']\n",
            "---------------------------------------------------\n",
            "05/09:\n",
            "  Consistently UP:   ['GILD']\n",
            "  Consistently DOWN: ['MOS']\n",
            "---------------------------------------------------\n",
            "05/10:\n",
            "  Consistently UP:   ['JKHY']\n",
            "---------------------------------------------------\n",
            "05/12:\n",
            "  Consistently DOWN: ['NTAP']\n",
            "---------------------------------------------------\n",
            "05/14:\n",
            "  Consistently UP:   ['AKAM', 'CVX', 'LIN', 'OKE', 'STX', 'STLD', 'WMB']\n",
            "---------------------------------------------------\n",
            "05/15:\n",
            "  Consistently UP:   ['WMB']\n",
            "---------------------------------------------------\n",
            "05/18:\n",
            "  Consistently DOWN: ['CPB']\n",
            "---------------------------------------------------\n",
            "05/21:\n",
            "  Consistently UP:   ['BA', 'CHRW', 'MMC', 'LUV']\n",
            "---------------------------------------------------\n",
            "05/28:\n",
            "  Consistently DOWN: ['NCLH']\n",
            "---------------------------------------------------\n",
            "05/29:\n",
            "  Consistently DOWN: ['NOC']\n",
            "---------------------------------------------------\n",
            "05/30:\n",
            "  Consistently UP:   ['GOOGL']\n",
            "---------------------------------------------------\n",
            "06/01:\n",
            "  Consistently UP:   ['LDOS', 'LYB']\n",
            "---------------------------------------------------\n",
            "06/02:\n",
            "  Consistently UP:   ['AMAT', 'AXON', 'DG', 'EMR', 'MMC', 'ROP', 'WBA']\n",
            "---------------------------------------------------\n",
            "06/03:\n",
            "  Consistently UP:   ['TGT']\n",
            "---------------------------------------------------\n",
            "06/04:\n",
            "  Consistently DOWN: ['ES']\n",
            "---------------------------------------------------\n",
            "06/06:\n",
            "  Consistently UP:   ['FANG', 'TSLA']\n",
            "---------------------------------------------------\n",
            "06/07:\n",
            "  Consistently UP:   ['EW']\n",
            "---------------------------------------------------\n",
            "06/12:\n",
            "  Consistently DOWN: ['MO', 'CL', 'STX']\n",
            "---------------------------------------------------\n",
            "06/14:\n",
            "  Consistently DOWN: ['EMN']\n",
            "---------------------------------------------------\n",
            "06/17:\n",
            "  Consistently UP:   ['DXCM']\n",
            "---------------------------------------------------\n",
            "06/18:\n",
            "  Consistently UP:   ['FICO', 'KDP', 'WST']\n",
            "---------------------------------------------------\n",
            "06/21:\n",
            "  Consistently UP:   ['WMT']\n",
            "---------------------------------------------------\n",
            "06/23:\n",
            "  Consistently DOWN: ['PCG']\n",
            "---------------------------------------------------\n",
            "06/24:\n",
            "  Consistently DOWN: ['CNC']\n",
            "---------------------------------------------------\n",
            "06/26:\n",
            "  Consistently DOWN: ['CME', 'WTW', 'ZTS']\n",
            "---------------------------------------------------\n",
            "06/30:\n",
            "  Consistently UP:   ['ALL', 'BLDR', 'CINF', 'TRV', 'VRSK']\n",
            "---------------------------------------------------\n",
            "07/01:\n",
            "  Consistently UP:   ['ABT', 'CPRT', 'EXPD', 'FIS', 'MCO', 'ORLY', 'POOL', 'PG', 'DIS']\n",
            "---------------------------------------------------\n",
            "07/02:\n",
            "  Consistently UP:   ['LLY']\n",
            "---------------------------------------------------\n",
            "07/03:\n",
            "  Consistently UP:   ['CPRT']\n",
            "---------------------------------------------------\n",
            "07/06:\n",
            "  Consistently UP:   ['NEE']\n",
            "---------------------------------------------------\n",
            "07/10:\n",
            "  Consistently UP:   ['SRE']\n",
            "---------------------------------------------------\n",
            "07/12:\n",
            "  Consistently UP:   ['APTV', 'CMI', 'TROW', 'URI']\n",
            "---------------------------------------------------\n",
            "07/15:\n",
            "  Consistently UP:   ['GL']\n",
            "---------------------------------------------------\n",
            "07/18:\n",
            "  Consistently UP:   ['KLAC']\n",
            "---------------------------------------------------\n",
            "07/20:\n",
            "  Consistently UP:   ['EBAY', 'META', 'MSFT', 'TXN', 'TMO']\n",
            "  Consistently DOWN: ['CAG']\n",
            "---------------------------------------------------\n",
            "07/21:\n",
            "  Consistently UP:   ['APO', 'KKR']\n",
            "---------------------------------------------------\n",
            "07/22:\n",
            "  Consistently UP:   ['LOW', 'SPGI', 'SBUX']\n",
            "---------------------------------------------------\n",
            "07/23:\n",
            "  Consistently UP:   ['NTRS']\n",
            "---------------------------------------------------\n",
            "07/24:\n",
            "  Consistently DOWN: ['EL']\n",
            "---------------------------------------------------\n",
            "07/26:\n",
            "  Consistently UP:   ['PLD']\n",
            "  Consistently DOWN: ['TGT']\n",
            "---------------------------------------------------\n",
            "07/29:\n",
            "  Consistently UP:   ['TGT']\n",
            "  Consistently DOWN: ['LUV']\n",
            "---------------------------------------------------\n",
            "07/31:\n",
            "  Consistently DOWN: ['VMC']\n",
            "---------------------------------------------------\n",
            "08/04:\n",
            "  Consistently DOWN: ['CB']\n",
            "---------------------------------------------------\n",
            "08/08:\n",
            "  Consistently UP:   ['AMP', 'CPB', 'COF', 'MTB']\n",
            "---------------------------------------------------\n",
            "08/09:\n",
            "  Consistently UP:   ['CVS', 'TRV']\n",
            "---------------------------------------------------\n",
            "08/12:\n",
            "  Consistently UP:   ['MKC']\n",
            "---------------------------------------------------\n",
            "08/13:\n",
            "  Consistently UP:   ['APD', 'GPN']\n",
            "---------------------------------------------------\n",
            "08/16:\n",
            "  Consistently UP:   ['AXON', 'NSC']\n",
            "---------------------------------------------------\n",
            "08/23:\n",
            "  Consistently DOWN: ['CVS', 'WMT']\n",
            "---------------------------------------------------\n",
            "08/25:\n",
            "  Consistently UP:   ['NXPI']\n",
            "---------------------------------------------------\n",
            "08/28:\n",
            "  Consistently UP:   ['DE']\n",
            "---------------------------------------------------\n",
            "08/30:\n",
            "  Consistently DOWN: ['NWSA', 'NWS']\n",
            "---------------------------------------------------\n",
            "08/31:\n",
            "  Consistently UP:   ['EQIX']\n",
            "---------------------------------------------------\n",
            "09/02:\n",
            "  Consistently UP:   ['NOW']\n",
            "---------------------------------------------------\n",
            "09/11:\n",
            "  Consistently UP:   ['ALL', 'AXP', 'BDX', 'HRL', 'MAS', 'PGR', 'PHM', 'VZ']\n",
            "---------------------------------------------------\n",
            "09/17:\n",
            "  Consistently UP:   ['CHD', 'LHX']\n",
            "---------------------------------------------------\n",
            "09/21:\n",
            "  Consistently DOWN: ['WYNN']\n",
            "---------------------------------------------------\n",
            "09/24:\n",
            "  Consistently DOWN: ['CHTR', 'IP']\n",
            "---------------------------------------------------\n",
            "10/10:\n",
            "  Consistently UP:   ['KDP']\n",
            "---------------------------------------------------\n",
            "10/16:\n",
            "  Consistently UP:   ['MLM', 'O']\n",
            "---------------------------------------------------\n",
            "10/20:\n",
            "  Consistently UP:   ['ADI']\n",
            "---------------------------------------------------\n",
            "10/26:\n",
            "  Consistently DOWN: ['SLB', 'SNA']\n",
            "---------------------------------------------------\n",
            "10/27:\n",
            "  Consistently DOWN: ['SNA']\n",
            "---------------------------------------------------\n",
            "10/31:\n",
            "  Consistently UP:   ['LKQ']\n",
            "---------------------------------------------------\n",
            "11/01:\n",
            "  Consistently UP:   ['BAC', 'RL', 'STT', 'VTRS']\n",
            "---------------------------------------------------\n",
            "11/03:\n",
            "  Consistently UP:   ['NKE']\n",
            "---------------------------------------------------\n",
            "11/04:\n",
            "  Consistently UP:   ['FTNT']\n",
            "---------------------------------------------------\n",
            "11/05:\n",
            "  Consistently UP:   ['CB', 'HON', 'J', 'KEY', 'MCD', 'RF', 'USB']\n",
            "---------------------------------------------------\n",
            "11/06:\n",
            "  Consistently UP:   ['AOS', 'AZO', 'ORCL', 'SNPS']\n",
            "---------------------------------------------------\n",
            "11/08:\n",
            "  Consistently UP:   ['MOS', 'VTRS']\n",
            "---------------------------------------------------\n",
            "11/10:\n",
            "  Consistently UP:   ['POOL']\n",
            "---------------------------------------------------\n",
            "11/11:\n",
            "  Consistently DOWN: ['AMGN']\n",
            "---------------------------------------------------\n",
            "11/12:\n",
            "  Consistently DOWN: ['XOM']\n",
            "---------------------------------------------------\n",
            "11/14:\n",
            "  Consistently UP:   ['URI']\n",
            "---------------------------------------------------\n",
            "11/15:\n",
            "  Consistently UP:   ['AES', 'ALL', 'CSCO', 'HRL', 'LDOS', 'TRGP']\n",
            "---------------------------------------------------\n",
            "11/16:\n",
            "  Consistently UP:   ['ROL']\n",
            "---------------------------------------------------\n",
            "11/17:\n",
            "  Consistently DOWN: ['TMO', 'TRMB', 'VMC']\n",
            "---------------------------------------------------\n",
            "11/19:\n",
            "  Consistently DOWN: ['ERIE']\n",
            "---------------------------------------------------\n",
            "11/20:\n",
            "  Consistently DOWN: ['CTSH']\n",
            "---------------------------------------------------\n",
            "11/21:\n",
            "  Consistently UP:   ['AOS', 'EMN', 'PSX', 'URI']\n",
            "---------------------------------------------------\n",
            "11/22:\n",
            "  Consistently UP:   ['BBY', 'LKQ', 'RL']\n",
            "---------------------------------------------------\n",
            "11/23:\n",
            "  Consistently UP:   ['HUM']\n",
            "---------------------------------------------------\n",
            "11/24:\n",
            "  Consistently UP:   ['FDS', 'GRMN', 'HD']\n",
            "---------------------------------------------------\n",
            "11/25:\n",
            "  Consistently UP:   ['TMO']\n",
            "---------------------------------------------------\n",
            "12/03:\n",
            "  Consistently DOWN: ['GILD']\n",
            "---------------------------------------------------\n",
            "12/06:\n",
            "  Consistently UP:   ['KR']\n",
            "---------------------------------------------------\n",
            "12/09:\n",
            "  Consistently DOWN: ['PFG']\n",
            "---------------------------------------------------\n",
            "12/13:\n",
            "  Consistently DOWN: ['AIZ', 'KEY']\n",
            "---------------------------------------------------\n",
            "12/24:\n",
            "  Consistently UP:   ['AOS', 'NEM']\n",
            "---------------------------------------------------\n",
            "12/25:\n",
            "  Consistently UP:   ['BXP', 'EQR', 'GPC', 'DOC', 'ROP', 'SNA', 'TDY', 'VTR']\n",
            "---------------------------------------------------\n",
            "12/26:\n",
            "  Consistently UP:   ['BXP', 'EQR', 'GPC', 'DOC', 'ROP', 'SNA', 'TDY', 'VTR']\n",
            "---------------------------------------------------\n",
            "12/27:\n",
            "  Consistently UP:   ['MMM', 'LNT', 'AEE', 'AWK', 'ETR', 'EVRG', 'GPC']\n",
            "---------------------------------------------------\n",
            "12/28:\n",
            "  Consistently DOWN: ['APA', 'BX', 'EPAM']\n",
            "---------------------------------------------------\n",
            "12/29:\n",
            "  Consistently UP:   ['AES', 'DG', 'EVRG', 'ES', 'XEL']\n",
            "---------------------------------------------------\n",
            "====================== DONE =======================\n"
          ]
        }
      ],
      "source": [
        "def consistently_up_down_by_date(tickers, start_year=2013, end_year=2023):\n",
        "    \"\"\"\n",
        "    For each calendar date (MM/DD) in a non-leap year, check if each stock\n",
        "    goes \"Up\" or \"Down\" on that date (or the next open trading day) for\n",
        "    every year in [start_year, end_year). If a stock is always \"Up\",\n",
        "    it is consistently up. If always \"Down\", it is consistently down.\n",
        "    Skips Feb 29 to simplify leap years.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tickers    : list of str\n",
        "        Ticker symbols to analyze.\n",
        "    start_year : int\n",
        "        First year to include (inclusive).\n",
        "    end_year   : int\n",
        "        Last year to exclude (typical Python range usage).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A dictionary:\n",
        "        {\n",
        "          (month, day): {\n",
        "             \"Up\":   [list_of_consistent_up_tickers],\n",
        "             \"Down\": [list_of_consistent_down_tickers]\n",
        "          },\n",
        "          ...\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Download daily data for each ticker.\n",
        "    #    We'll store dataframes in a dictionary: {ticker: DataFrame, ...}\n",
        "    #    Pull from (start_year-1) to end_year so we have the previous day coverage.\n",
        "    full_start_date = f\"{start_year-1}-12-31\"\n",
        "    full_end_date   = f\"{end_year}-12-31\"\n",
        "\n",
        "    data_dict = {}\n",
        "    for ticker in tickers:\n",
        "        print(f\"Downloading data for {ticker}...\")\n",
        "        df = yf.download(\n",
        "            ticker,\n",
        "            start=full_start_date,\n",
        "            end=full_end_date,\n",
        "            interval=\"1d\",\n",
        "            auto_adjust=False,\n",
        "            progress=False\n",
        "        )\n",
        "\n",
        "        if df.empty:\n",
        "            print(f\"No data for {ticker}. Skipping.\")\n",
        "            data_dict[ticker] = None\n",
        "            continue\n",
        "\n",
        "        # --- Flatten columns if there's a MultiIndex (can happen with new yfinance) ---\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
        "\n",
        "        # If there's a single \"Close_...\" column, rename it to \"Close\"\n",
        "        close_cols = [c for c in df.columns if \"Close\" in c and \"Adj\" not in c]\n",
        "        # Example: \"Close_AAPL\" => \"Close\"\n",
        "        if len(close_cols) == 1:\n",
        "            df.rename(columns={close_cols[0]: \"Close\"}, inplace=True)\n",
        "\n",
        "        # We now expect \"Close\" in columns\n",
        "        if \"Close\" not in df.columns:\n",
        "            print(f\"Could not find a single 'Close' column for {ticker}. Skipping.\")\n",
        "            data_dict[ticker] = None\n",
        "            continue\n",
        "\n",
        "        # Sort by index date ascending\n",
        "        df.sort_index(inplace=True)\n",
        "\n",
        "        # Create 'Prev Close' for day-to-day comparison\n",
        "        df[\"Prev Close\"] = df[\"Close\"].shift(1)\n",
        "\n",
        "        data_dict[ticker] = df\n",
        "\n",
        "    # 2) Prepare a structure to hold results: date -> { \"Up\": [], \"Down\": [] }\n",
        "    #    We'll skip Feb 29 for simplicity (leap years).\n",
        "    days_in_month = {\n",
        "        1:31, 2:28, 3:31, 4:30, 5:31, 6:30,\n",
        "        7:31, 8:31, 9:30, 10:31, 11:30, 12:31\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for month in range(1, 13):\n",
        "        for day in range(1, days_in_month[month] + 1):\n",
        "            md_key = (month, day)\n",
        "            results[md_key] = {\"Up\": [], \"Down\": []}\n",
        "\n",
        "    num_years = end_year - start_year  # e.g. 2023 - 2013 = 10\n",
        "\n",
        "    def check_ticker_for_date(df, month, day):\n",
        "        \"\"\"\n",
        "        Return 'Up' if the ticker is up for all years,\n",
        "               'Down' if it's down for all years,\n",
        "               None if it's inconsistent or missing data.\n",
        "        \"\"\"\n",
        "        if df is None or df.empty:\n",
        "            return None\n",
        "\n",
        "        all_up = True\n",
        "        all_down = True\n",
        "\n",
        "        for year in range(start_year, end_year):\n",
        "            target_date = datetime.date(year, month, day)\n",
        "\n",
        "            # Filter df to rows >= target_date\n",
        "            temp_df = df.loc[df.index >= pd.to_datetime(target_date)]\n",
        "            if temp_df.empty:\n",
        "                return None  # no data for that date/year\n",
        "\n",
        "            # first trading day on/after target_date\n",
        "            row = temp_df.iloc[0]\n",
        "            close_price = row[\"Close\"]\n",
        "            prev_close  = row[\"Prev Close\"]\n",
        "            if pd.isna(close_price) or pd.isna(prev_close):\n",
        "                return None\n",
        "\n",
        "            if close_price > prev_close:\n",
        "                # up day\n",
        "                all_down = False\n",
        "            elif close_price < prev_close:\n",
        "                # down day\n",
        "                all_up = False\n",
        "            else:\n",
        "                # equal => neither up nor down\n",
        "                all_up = False\n",
        "                all_down = False\n",
        "\n",
        "            # If both are false, no need to continue\n",
        "            if not all_up and not all_down:\n",
        "                return None\n",
        "\n",
        "        # End of loop => we have a consistent direction if one is still True\n",
        "        if all_up:\n",
        "            return \"Up\"\n",
        "        elif all_down:\n",
        "            return \"Down\"\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # 3) For each date, determine if each ticker is consistently up or down\n",
        "    for (month, day) in results.keys():\n",
        "        for ticker in tickers:\n",
        "            direction = check_ticker_for_date(data_dict[ticker], month, day)\n",
        "            if direction == \"Up\":\n",
        "                results[(month, day)][\"Up\"].append(ticker)\n",
        "            elif direction == \"Down\":\n",
        "                results[(month, day)][\"Down\"].append(ticker)\n",
        "            # else do nothing\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ==========================================================================\n",
        "# EXAMPLE USAGE\n",
        "# ==========================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    #tickers_list = [\n",
        "     #   \"AAPL\", \"MSFT\", \"TSLA\", \"AMZN\", \"GOOG\", \"META\", \"NVDA\",\n",
        "     #   \"IBM\", \"NFLX\", \"INTC\", \"ADBE\", \"ORCL\", \"KO\", \"PEP\"\n",
        "   # ]\n",
        "\n",
        "    tickers_list = [\"MMM\", \"AOS\", \"ABT\", \"ABBV\", \"ACN\", \"ADBE\", \"AMD\", \"AES\",\n",
        "                    \"AFL\", \"A\", \"APD\", \"ABNB\", \"AKAM\", \"ALB\", \"ARE\", \"ALGN\", \"ALLE\",\n",
        "                    \"LNT\", \"ALL\", \"GOOGL\", \"GOOG\", \"MO\", \"AMZN\", \"AMCR\", \"AEE\", \"AEP\", \"AXP\",\n",
        "                    \"AIG\", \"AMT\", \"AWK\", \"AMP\", \"AME\", \"AMGN\", \"APH\", \"ADI\", \"ANSS\", \"AON\", \"APA\", \"APO\", \"AAPL\",\n",
        "                    \"AMAT\", \"APTV\", \"ACGL\", \"ADM\", \"ANET\", \"AJG\", \"AIZ\", \"T\", \"ATO\", \"ADSK\", \"ADP\", \"AZO\", \"AVB\", \"AVY\", \"AXON\", \"BKR\",\n",
        "                    \"BALL\", \"BAC\", \"BAX\", \"BDX\", \"BRK.B\", \"BBY\", \"TECH\", \"BIIB\", \"BLK\", \"BX\", \"BK\", \"BA\", \"BKNG\", \"BSX\", \"BMY\", \"AVGO\",\n",
        "                    \"BR\", \"BRO\", \"BF.B\", \"BLDR\", \"BG\", \"BXP\", \"CHRW\", \"CDNS\", \"CZR\", \"CPT\", \"CPB\", \"COF\", \"CAH\", \"KMX\", \"CCL\", \"CARR\", \"CAT\",\n",
        "                    \"CBOE\", \"CBRE\", \"CDW\", \"COR\", \"CNC\", \"CNP\", \"CF\", \"CRL\", \"SCHW\", \"CHTR\", \"CVX\", \"CMG\", \"CB\", \"CHD\", \"CI\", \"CINF\",\n",
        "                    \"CTAS\", \"CSCO\", \"C\", \"CFG\", \"CLX\", \"CME\", \"CMS\", \"KO\", \"CTSH\", \"CL\", \"CMCSA\", \"CAG\", \"COP\", \"ED\", \"STZ\", \"CEG\",\n",
        "                    \"COO\", \"CPRT\", \"GLW\", \"CPAY\", \"CTVA\", \"CSGP\", \"COST\", \"CTRA\", \"CRWD\", \"CCI\", \"CSX\", \"CMI\", \"CVS\", \"DHR\", \"DRI\", \"DVA\",\n",
        "                    \"DAY\", \"DECK\", \"DE\", \"DELL\", \"DAL\", \"DVN\", \"DXCM\", \"FANG\", \"DLR\", \"DFS\", \"DG\", \"DLTR\", \"D\", \"DPZ\", \"DASH\", \"DOV\", \"DOW\", \"DHI\", \"DTE\",\n",
        "                    \"DUK\", \"DD\", \"EMN\", \"ETN\", \"EBAY\", \"ECL\", \"EIX\", \"EW\", \"EA\", \"ELV\", \"EMR\", \"ENPH\", \"ETR\", \"EOG\", \"EPAM\", \"EQT\", \"EFX\", \"EQIX\", \"EQR\",\n",
        "                    \"ERIE\", \"ESS\", \"EL\", \"EG\", \"EVRG\", \"ES\", \"EXC\", \"EXE\", \"EXPE\", \"EXPD\", \"EXR\", \"XOM\", \"FFIV\", \"FDS\", \"FICO\", \"FAST\", \"FRT\", \"FDX\", \"FIS\",\n",
        "                    \"FITB\", \"FSLR\", \"FE\", \"FI\", \"F\", \"FTNT\", \"FTV\", \"FOXA\", \"FOX\", \"BEN\", \"FCX\", \"GRMN\", \"IT\", \"GE\", \"GEHC\", \"GEV\", \"GEN\", \"GNRC\", \"GD\",\n",
        "                    \"GIS\", \"GM\", \"GPC\", \"GILD\", \"GPN\", \"GL\", \"GDDY\", \"GS\", \"HAL\", \"HIG\", \"HAS\", \"HCA\", \"DOC\", \"HSIC\", \"HSY\", \"HES\", \"HPE\", \"HLT\",\n",
        "                    \"HOLX\", \"HD\", \"HON\", \"HRL\", \"HST\", \"HWM\", \"HPQ\", \"HUBB\", \"HUM\", \"HBAN\", \"HII\", \"IBM\", \"IEX\", \"IDXX\", \"ITW\", \"INCY\", \"IR\", \"PODD\",\n",
        "                    \"INTC\", \"ICE\", \"IFF\", \"IP\", \"IPG\", \"INTU\", \"ISRG\", \"IVZ\", \"INVH\", \"IQV\", \"IRM\", \"JBHT\", \"JBL\", \"JKHY\", \"J\", \"JNJ\", \"JCI\", \"JPM\",\n",
        "                    \"JNPR\", \"K\", \"KVUE\", \"KDP\", \"KEY\", \"KEYS\", \"KMB\", \"KIM\", \"KMI\", \"KKR\", \"KLAC\", \"KHC\", \"KR\", \"LHX\", \"LH\", \"LRCX\", \"LW\", \"LVS\",\n",
        "                    \"LDOS\", \"LEN\", \"LII\", \"LLY\", \"LIN\", \"LYV\", \"LKQ\", \"LMT\", \"L\", \"LOW\", \"LULU\", \"LYB\", \"MTB\", \"MPC\", \"MKTX\", \"MAR\", \"MMC\", \"MLM\",\n",
        "                    \"MAS\", \"MA\", \"MTCH\", \"MKC\", \"MCD\", \"MCK\", \"MDT\", \"MRK\", \"META\", \"MET\", \"MTD\", \"MGM\", \"MCHP\", \"MU\", \"MSFT\", \"MAA\", \"MRNA\", \"MHK\",\n",
        "                    \"MOH\", \"TAP\", \"MDLZ\", \"MPWR\", \"MNST\", \"MCO\", \"MS\", \"MOS\", \"MSI\", \"MSCI\", \"NDAQ\", \"NTAP\", \"NFLX\", \"NEM\", \"NWSA\", \"NWS\", \"NEE\",\n",
        "                    \"NKE\", \"NI\", \"NDSN\", \"NSC\", \"NTRS\", \"NOC\", \"NCLH\", \"NRG\", \"NUE\", \"NVDA\", \"NVR\", \"NXPI\", \"ORLY\", \"OXY\", \"ODFL\", \"OMC\", \"ON\",\n",
        "                    \"OKE\", \"ORCL\", \"OTIS\", \"PCAR\", \"PKG\", \"PLTR\", \"PANW\", \"PARA\", \"PH\", \"PAYX\", \"PAYC\", \"PYPL\", \"PNR\", \"PEP\", \"PFE\", \"PCG\", \"PM\",\n",
        "                    \"PSX\", \"PNW\", \"PNC\", \"POOL\", \"PPG\", \"PPL\", \"PFG\", \"PG\", \"PGR\", \"PLD\", \"PRU\", \"PEG\", \"PTC\", \"PSA\", \"PHM\", \"PWR\", \"QCOM\", \"DGX\",\n",
        "                    \"RL\", \"RJF\", \"RTX\", \"O\", \"REG\", \"REGN\", \"RF\", \"RSG\", \"RMD\", \"RVTY\", \"ROK\", \"ROL\", \"ROP\", \"ROST\", \"RCL\", \"SPGI\", \"CRM\", \"SBAC\",\n",
        "                    \"SLB\", \"STX\", \"SRE\", \"NOW\", \"SHW\", \"SPG\", \"SWKS\", \"SJM\", \"SW\", \"SNA\", \"SOLV\", \"SO\", \"LUV\", \"SWK\", \"SBUX\", \"STT\", \"STLD\", \"STE\",\n",
        "                    \"SYK\", \"SMCI\", \"SYF\", \"SNPS\", \"SYY\", \"TMUS\", \"TROW\", \"TTWO\", \"TPR\", \"TRGP\", \"TGT\", \"TEL\", \"TDY\", \"TER\", \"TSLA\", \"TXN\", \"TPL\",\n",
        "                    \"TXT\", \"TMO\", \"TJX\", \"TKO\", \"TSCO\", \"TT\", \"TDG\", \"TRV\", \"TRMB\", \"TFC\", \"TYL\", \"TSN\", \"USB\", \"UBER\", \"UDR\", \"ULTA\", \"UNP\", \"UAL\",\n",
        "                    \"UPS\", \"URI\", \"UNH\", \"UHS\", \"VLO\", \"VTR\", \"VLTO\", \"VRSN\", \"VRSK\", \"VZ\", \"VRTX\", \"VTRS\", \"VICI\", \"V\", \"VST\", \"VMC\", \"WRB\", \"GWW\",\n",
        "                    \"WAB\", \"WBA\", \"WMT\", \"DIS\", \"WBD\", \"WM\", \"WAT\", \"WEC\", \"WFC\", \"WELL\", \"WST\", \"WDC\", \"WY\", \"WSM\", \"WMB\", \"WTW\", \"WDAY\", \"WYNN\",\n",
        "                    \"XEL\", \"XYL\", \"YUM\", \"ZBRA\", \"ZBH\", \"ZTS\"]\n",
        "\n",
        "    # We'll check 10 years: from 2013 through 2022\n",
        "    start_yr = 2013\n",
        "    end_yr   = 2023  # up to 2022 (exclusive)\n",
        "\n",
        "    final_results = consistently_up_down_by_date(\n",
        "        tickers_list,\n",
        "        start_year=start_yr,\n",
        "        end_year=end_yr\n",
        "    )\n",
        "\n",
        "    # Print only the dates that have at least 1 consistently up or down stock\n",
        "    print(\"\\n\\n==================== FINAL RESULTS ====================\")\n",
        "    for (month, day), dir_dict in sorted(final_results.items()):\n",
        "        up_tickers = dir_dict[\"Up\"]\n",
        "        down_tickers = dir_dict[\"Down\"]\n",
        "        if up_tickers or down_tickers:\n",
        "            print(f\"{month:02d}/{day:02d}:\")\n",
        "            if up_tickers:\n",
        "                print(f\"  Consistently UP:   {up_tickers}\")\n",
        "            if down_tickers:\n",
        "                print(f\"  Consistently DOWN: {down_tickers}\")\n",
        "            print(\"---------------------------------------------------\")\n",
        "    print(\"====================== DONE =======================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backtesting"
      ],
      "metadata": {
        "id": "CB3j3-gLouK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install backtesting yfinance pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GySONlQcozLR",
        "outputId": "a77aee8d-9898-4b07-adc3-b05d665b5411"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting backtesting\n",
            "  Downloading backtesting-0.6.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: bokeh!=3.0.*,!=3.2.*,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from backtesting) (3.6.3)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=1.4.0->backtesting) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=1.4.0->backtesting) (1.3.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.11/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=1.4.0->backtesting) (24.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=1.4.0->backtesting) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=1.4.0->backtesting) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=1.4.0->backtesting) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=1.4.0->backtesting) (2025.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh!=3.0.*,!=3.2.*,>=1.4.0->backtesting) (3.0.2)\n",
            "Downloading backtesting-0.6.4-py3-none-any.whl (191 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.4/191.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: backtesting\n",
            "Successfully installed backtesting-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Library Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from backtesting import Backtest, Strategy"
      ],
      "metadata": {
        "id": "pEkm6ypvrFEB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two ranges:\n",
        "TRAIN_START = 2013\n",
        "TRAIN_END   = 2021  # up to 2020 inclusive in your function\n",
        "TEST_START_DATE = \"2021-01-01\"\n",
        "TEST_END_DATE   = \"2023-01-01\"\n",
        "\n",
        "tickers_list = [\"AAPL\", \"MSFT\", \"TSLA\", \"LNT\", \"ALL\", \"GOOGL\", \"GOOG\", \"MO\", \"AMZN\", \"AMCR\", \"AEE\", \"AEP\", \"AXP\",\n",
        "                    \"AIG\", \"AMT\", \"AWK\", \"AMP\", \"AME\", \"AMGN\", \"APH\", \"ADI\", \"ANSS\", \"AON\", \"APA\", \"APO\",\"AMAT\", \"APTV\", \"ACGL\", \"ADM\", \"ANET\", \"AJG\", \"AIZ\", \"T\", \"ATO\", \"ADSK\", \"ADP\", \"AZO\", \"AVB\", \"AVY\", \"AXON\", \"BKR\",\n",
        "                    \"BALL\", \"BAC\", \"BAX\", \"BDX\", \"BRK.B\", \"BBY\", \"TECH\", \"BIIB\", \"BLK\", \"BX\", \"BK\", \"BA\", \"BKNG\", \"BSX\", \"BMY\", \"AVGO\",\n",
        "                    \"BR\", \"BRO\", \"BF.B\", \"BLDR\", \"BG\", \"BXP\", \"CHRW\", \"CDNS\", \"CZR\", \"CPT\", \"CPB\", \"COF\", \"CAH\", \"KMX\", \"CCL\", \"CARR\", \"CAT\",\n",
        "                    \"CBOE\", \"CBRE\", \"CDW\", \"COR\", \"CNC\", \"CNP\", \"CF\", \"CRL\", \"SCHW\", \"CHTR\", \"CVX\", \"CMG\", \"CB\", \"CHD\", \"CI\", \"CINF\",\n",
        "                    \"CTAS\", \"CSCO\", \"C\", \"CFG\", \"CLX\", \"CME\", \"CMS\", \"KO\", \"CTSH\", \"CL\", \"CMCSA\", \"CAG\", \"COP\", \"ED\", \"STZ\", \"CEG\",\n",
        "                    \"COO\", \"CPRT\", \"GLW\", \"CPAY\", \"CTVA\", \"CSGP\", \"COST\", \"CTRA\", \"CRWD\", \"CCI\", \"CSX\", \"CMI\", \"CVS\", \"DHR\", \"DRI\", \"DVA\",\n",
        "                    \"DAY\", \"DECK\", \"DE\", \"DELL\", \"DAL\", \"DVN\", \"DXCM\", \"FANG\", \"DLR\", \"DFS\", \"DG\", \"DLTR\", \"D\", \"DPZ\", \"DASH\", \"DOV\", \"DOW\", \"DHI\", \"DTE\",\n",
        "                    \"DUK\", \"DD\", \"EMN\", \"ETN\", \"EBAY\", \"ECL\", \"EIX\", \"EW\", \"EA\", \"ELV\", \"EMR\", \"ENPH\", \"ETR\", \"EOG\", \"EPAM\", \"EQT\", \"EFX\", \"EQIX\", \"EQR\",\n",
        "                    \"ERIE\", \"ESS\", \"EL\", \"EG\", \"EVRG\", \"ES\", \"EXC\", \"EXE\", \"EXPE\", \"EXPD\", \"EXR\", \"XOM\", \"FFIV\", \"FDS\", \"FICO\", \"FAST\", \"FRT\", \"FDX\", \"FIS\",\n",
        "                    \"FITB\", \"FSLR\", \"FE\", \"FI\", \"F\", \"FTNT\", \"FTV\", \"FOXA\", \"FOX\", \"BEN\", \"FCX\", \"GRMN\", \"IT\", \"GE\", \"GEHC\", \"GEV\", \"GEN\", \"GNRC\", \"GD\",\n",
        "                    \"GIS\", \"GM\", \"GPC\", \"GILD\", \"GPN\", \"GL\", \"GDDY\", \"GS\", \"HAL\", \"HIG\", \"HAS\", \"HCA\", \"DOC\", \"HSIC\", \"HSY\", \"HES\", \"HPE\", \"HLT\",\n",
        "                    \"HOLX\", \"HD\", \"HON\", \"HRL\", \"HST\", \"HWM\", \"HPQ\", \"HUBB\", \"HUM\", \"HBAN\", \"HII\", \"IBM\", \"IEX\", \"IDXX\", \"ITW\", \"INCY\", \"IR\", \"PODD\",\n",
        "                    \"INTC\", \"ICE\", \"IFF\", \"IP\", \"IPG\", \"INTU\", \"ISRG\", \"IVZ\", \"INVH\", \"IQV\", \"IRM\", \"JBHT\", \"JBL\", \"JKHY\", \"J\", \"JNJ\", \"JCI\", \"JPM\",\n",
        "                    \"JNPR\", \"K\", \"KVUE\", \"KDP\", \"KEY\", \"KEYS\", \"KMB\", \"KIM\",]"
      ],
      "metadata": {
        "id": "DV9Zs8w8tA0o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "# Suppose your function is defined in the same notebook or imported from a file:\n",
        "# from your_module import consistently_up_down_by_date\n",
        "\n",
        "consistency_signals = consistently_up_down_by_date(\n",
        "    tickers_list,\n",
        "    start_year=TRAIN_START,\n",
        "    end_year=TRAIN_END  # so we capture 2013..2020\n",
        ")\n",
        "\n",
        "# consistency_signals is a dict of:\n",
        "#    (month, day) -> {\"Up\": [tickers], \"Down\": [tickers]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrG0NAjlv0mS",
        "outputId": "78b4f838-11ce-4f80-a471-e01570608174"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for AAPL...\n",
            "Downloading data for MSFT...\n",
            "Downloading data for TSLA...\n",
            "Downloading data for LNT...\n",
            "Downloading data for ALL...\n",
            "Downloading data for GOOGL...\n",
            "Downloading data for GOOG...\n",
            "Downloading data for MO...\n",
            "Downloading data for AMZN...\n",
            "Downloading data for AMCR...\n",
            "Downloading data for AEE...\n",
            "Downloading data for AEP...\n",
            "Downloading data for AXP...\n",
            "Downloading data for AIG...\n",
            "Downloading data for AMT...\n",
            "Downloading data for AWK...\n",
            "Downloading data for AMP...\n",
            "Downloading data for AME...\n",
            "Downloading data for AMGN...\n",
            "Downloading data for APH...\n",
            "Downloading data for ADI...\n",
            "Downloading data for ANSS...\n",
            "Downloading data for AON...\n",
            "Downloading data for APA...\n",
            "Downloading data for APO...\n",
            "Downloading data for AMAT...\n",
            "Downloading data for APTV...\n",
            "Downloading data for ACGL...\n",
            "Downloading data for ADM...\n",
            "Downloading data for ANET...\n",
            "Downloading data for AJG...\n",
            "Downloading data for AIZ...\n",
            "Downloading data for T...\n",
            "Downloading data for ATO...\n",
            "Downloading data for ADSK...\n",
            "Downloading data for ADP...\n",
            "Downloading data for AZO...\n",
            "Downloading data for AVB...\n",
            "Downloading data for AVY...\n",
            "Downloading data for AXON...\n",
            "Downloading data for BKR...\n",
            "Downloading data for BALL...\n",
            "Downloading data for BAC...\n",
            "Downloading data for BAX...\n",
            "Downloading data for BDX...\n",
            "Downloading data for BRK.B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for BRK.B. Skipping.\n",
            "Downloading data for BBY...\n",
            "Downloading data for TECH...\n",
            "Downloading data for BIIB...\n",
            "Downloading data for BLK...\n",
            "Downloading data for BX...\n",
            "Downloading data for BK...\n",
            "Downloading data for BA...\n",
            "Downloading data for BKNG...\n",
            "Downloading data for BSX...\n",
            "Downloading data for BMY...\n",
            "Downloading data for AVGO...\n",
            "Downloading data for BR...\n",
            "Downloading data for BRO...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2021-12-31)')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for BF.B...\n",
            "No data for BF.B. Skipping.\n",
            "Downloading data for BLDR...\n",
            "Downloading data for BG...\n",
            "Downloading data for BXP...\n",
            "Downloading data for CHRW...\n",
            "Downloading data for CDNS...\n",
            "Downloading data for CZR...\n",
            "Downloading data for CPT...\n",
            "Downloading data for CPB...\n",
            "Downloading data for COF...\n",
            "Downloading data for CAH...\n",
            "Downloading data for KMX...\n",
            "Downloading data for CCL...\n",
            "Downloading data for CARR...\n",
            "Downloading data for CAT...\n",
            "Downloading data for CBOE...\n",
            "Downloading data for CBRE...\n",
            "Downloading data for CDW...\n",
            "Downloading data for COR...\n",
            "Downloading data for CNC...\n",
            "Downloading data for CNP...\n",
            "Downloading data for CF...\n",
            "Downloading data for CRL...\n",
            "Downloading data for SCHW...\n",
            "Downloading data for CHTR...\n",
            "Downloading data for CVX...\n",
            "Downloading data for CMG...\n",
            "Downloading data for CB...\n",
            "Downloading data for CHD...\n",
            "Downloading data for CI...\n",
            "Downloading data for CINF...\n",
            "Downloading data for CTAS...\n",
            "Downloading data for CSCO...\n",
            "Downloading data for C...\n",
            "Downloading data for CFG...\n",
            "Downloading data for CLX...\n",
            "Downloading data for CME...\n",
            "Downloading data for CMS...\n",
            "Downloading data for KO...\n",
            "Downloading data for CTSH...\n",
            "Downloading data for CL...\n",
            "Downloading data for CMCSA...\n",
            "Downloading data for CAG...\n",
            "Downloading data for COP...\n",
            "Downloading data for ED...\n",
            "Downloading data for STZ...\n",
            "Downloading data for CEG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['CEG']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2021-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1356930000, endDate = 1640926800\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for CEG. Skipping.\n",
            "Downloading data for COO...\n",
            "Downloading data for CPRT...\n",
            "Downloading data for GLW...\n",
            "Downloading data for CPAY...\n",
            "Downloading data for CTVA...\n",
            "Downloading data for CSGP...\n",
            "Downloading data for COST...\n",
            "Downloading data for CTRA...\n",
            "Downloading data for CRWD...\n",
            "Downloading data for CCI...\n",
            "Downloading data for CSX...\n",
            "Downloading data for CMI...\n",
            "Downloading data for CVS...\n",
            "Downloading data for DHR...\n",
            "Downloading data for DRI...\n",
            "Downloading data for DVA...\n",
            "Downloading data for DAY...\n",
            "Downloading data for DECK...\n",
            "Downloading data for DE...\n",
            "Downloading data for DELL...\n",
            "Downloading data for DAL...\n",
            "Downloading data for DVN...\n",
            "Downloading data for DXCM...\n",
            "Downloading data for FANG...\n",
            "Downloading data for DLR...\n",
            "Downloading data for DFS...\n",
            "Downloading data for DG...\n",
            "Downloading data for DLTR...\n",
            "Downloading data for D...\n",
            "Downloading data for DPZ...\n",
            "Downloading data for DASH...\n",
            "Downloading data for DOV...\n",
            "Downloading data for DOW...\n",
            "Downloading data for DHI...\n",
            "Downloading data for DTE...\n",
            "Downloading data for DUK...\n",
            "Downloading data for DD...\n",
            "Downloading data for EMN...\n",
            "Downloading data for ETN...\n",
            "Downloading data for EBAY...\n",
            "Downloading data for ECL...\n",
            "Downloading data for EIX...\n",
            "Downloading data for EW...\n",
            "Downloading data for EA...\n",
            "Downloading data for ELV...\n",
            "Downloading data for EMR...\n",
            "Downloading data for ENPH...\n",
            "Downloading data for ETR...\n",
            "Downloading data for EOG...\n",
            "Downloading data for EPAM...\n",
            "Downloading data for EQT...\n",
            "Downloading data for EFX...\n",
            "Downloading data for EQIX...\n",
            "Downloading data for EQR...\n",
            "Downloading data for ERIE...\n",
            "Downloading data for ESS...\n",
            "Downloading data for EL...\n",
            "Downloading data for EG...\n",
            "Downloading data for EVRG...\n",
            "Downloading data for ES...\n",
            "Downloading data for EXC...\n",
            "Downloading data for EXE...\n",
            "Downloading data for EXPE...\n",
            "Downloading data for EXPD...\n",
            "Downloading data for EXR...\n",
            "Downloading data for XOM...\n",
            "Downloading data for FFIV...\n",
            "Downloading data for FDS...\n",
            "Downloading data for FICO...\n",
            "Downloading data for FAST...\n",
            "Downloading data for FRT...\n",
            "Downloading data for FDX...\n",
            "Downloading data for FIS...\n",
            "Downloading data for FITB...\n",
            "Downloading data for FSLR...\n",
            "Downloading data for FE...\n",
            "Downloading data for FI...\n",
            "Downloading data for F...\n",
            "Downloading data for FTNT...\n",
            "Downloading data for FTV...\n",
            "Downloading data for FOXA...\n",
            "Downloading data for FOX...\n",
            "Downloading data for BEN...\n",
            "Downloading data for FCX...\n",
            "Downloading data for GRMN...\n",
            "Downloading data for IT...\n",
            "Downloading data for GE...\n",
            "Downloading data for GEHC...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['GEHC']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2021-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1356930000, endDate = 1640926800\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for GEHC. Skipping.\n",
            "Downloading data for GEV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['GEV']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2021-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1356930000, endDate = 1640926800\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for GEV. Skipping.\n",
            "Downloading data for GEN...\n",
            "Downloading data for GNRC...\n",
            "Downloading data for GD...\n",
            "Downloading data for GIS...\n",
            "Downloading data for GM...\n",
            "Downloading data for GPC...\n",
            "Downloading data for GILD...\n",
            "Downloading data for GPN...\n",
            "Downloading data for GL...\n",
            "Downloading data for GDDY...\n",
            "Downloading data for GS...\n",
            "Downloading data for HAL...\n",
            "Downloading data for HIG...\n",
            "Downloading data for HAS...\n",
            "Downloading data for HCA...\n",
            "Downloading data for DOC...\n",
            "Downloading data for HSIC...\n",
            "Downloading data for HSY...\n",
            "Downloading data for HES...\n",
            "Downloading data for HPE...\n",
            "Downloading data for HLT...\n",
            "Downloading data for HOLX...\n",
            "Downloading data for HD...\n",
            "Downloading data for HON...\n",
            "Downloading data for HRL...\n",
            "Downloading data for HST...\n",
            "Downloading data for HWM...\n",
            "Downloading data for HPQ...\n",
            "Downloading data for HUBB...\n",
            "Downloading data for HUM...\n",
            "Downloading data for HBAN...\n",
            "Downloading data for HII...\n",
            "Downloading data for IBM...\n",
            "Downloading data for IEX...\n",
            "Downloading data for IDXX...\n",
            "Downloading data for ITW...\n",
            "Downloading data for INCY...\n",
            "Downloading data for IR...\n",
            "Downloading data for PODD...\n",
            "Downloading data for INTC...\n",
            "Downloading data for ICE...\n",
            "Downloading data for IFF...\n",
            "Downloading data for IP...\n",
            "Downloading data for IPG...\n",
            "Downloading data for INTU...\n",
            "Downloading data for ISRG...\n",
            "Downloading data for IVZ...\n",
            "Downloading data for INVH...\n",
            "Downloading data for IQV...\n",
            "Downloading data for IRM...\n",
            "Downloading data for JBHT...\n",
            "Downloading data for JBL...\n",
            "Downloading data for JKHY...\n",
            "Downloading data for J...\n",
            "Downloading data for JNJ...\n",
            "Downloading data for JCI...\n",
            "Downloading data for JPM...\n",
            "Downloading data for JNPR...\n",
            "Downloading data for K...\n",
            "Downloading data for KVUE...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['KVUE']: YFPricesMissingError('possibly delisted; no price data found  (1d 2012-12-31 -> 2021-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1356930000, endDate = 1640926800\")')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for KVUE. Skipping.\n",
            "Downloading data for KDP...\n",
            "Downloading data for KEY...\n",
            "Downloading data for KEYS...\n",
            "Downloading data for KMB...\n",
            "Downloading data for KIM...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = {}\n",
        "for ticker in tickers_list:\n",
        "    df = yf.download(\n",
        "        ticker,\n",
        "        start=TEST_START_DATE,\n",
        "        end=TEST_END_DATE,\n",
        "        progress=False\n",
        "    )\n",
        "    df.sort_index(inplace=True)\n",
        "\n",
        "    # Keep the relevant columns\n",
        "    test_data[ticker] = df[[\"Open\", \"High\", \"Low\", \"Close\"]].copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCysOjfmwLql",
        "outputId": "036ae34f-3e6a-4e05-8da7-68b93467dec9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 2021-01-01 -> 2023-01-01)')\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['GEV']: YFPricesMissingError('possibly delisted; no price data found  (1d 2021-01-01 -> 2023-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 1609477200, endDate = 1672549200\")')\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['KVUE']: YFPricesMissingError('possibly delisted; no price data found  (1d 2021-01-01 -> 2023-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 1609477200, endDate = 1672549200\")')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_signal_map = {}\n",
        "\n",
        "for ticker in tickers_list:\n",
        "    # Each ticker has a dictionary from (month, day) -> \"Up\"/\"Down\"/None\n",
        "    md_signals = {}\n",
        "    for (m,d), updown_dict in consistency_signals.items():\n",
        "        if ticker in updown_dict[\"Up\"]:\n",
        "            md_signals[(m,d)] = \"Up\"\n",
        "        elif ticker in updown_dict[\"Down\"]:\n",
        "            md_signals[(m,d)] = \"Down\"\n",
        "        else:\n",
        "            md_signals[(m,d)] = None\n",
        "    ticker_signal_map[ticker] = md_signals"
      ],
      "metadata": {
        "id": "mPycYOI-x_Qo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConsistentUpDownStrategy(Strategy):\n",
        "    def init(self):\n",
        "        pass\n",
        "\n",
        "    def next(self):\n",
        "        # Close any open position from yesterday\n",
        "        # (we're only holding for 1 day in this example)\n",
        "        if self.position:\n",
        "            self.position.close()\n",
        "\n",
        "        # Check current date\n",
        "        current_date = self.data.index[-1]\n",
        "        m, d = current_date.month, current_date.day\n",
        "\n",
        "        # See if there's a signal for this date:\n",
        "        signal = self.signal_map.get((m, d), None)\n",
        "\n",
        "        if signal == \"Up\":\n",
        "            # Enter a long position at today's open\n",
        "            self.buy()\n",
        "        elif signal == \"Down\":\n",
        "            # Enter a short position at today's open\n",
        "            self.sell()"
      ],
      "metadata": {
        "id": "eYrOAWcgyENu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConsistentUpDownStrategy(Strategy):\n",
        "    def init(self):\n",
        "        # We can store the map in the Strategy instance\n",
        "        # The Backtest will pass it in as a parameter\n",
        "        self.signal_map = self.custom_signal_map\n",
        "\n",
        "    def next(self):\n",
        "        if self.position:\n",
        "            self.position.close()\n",
        "\n",
        "        current_date = self.data.index[-1]\n",
        "        m, d = current_date.month, current_date.day\n",
        "\n",
        "        signal = self.signal_map.get((m, d), None)\n",
        "        if signal == \"Up\":\n",
        "            self.buy()\n",
        "        elif signal == \"Down\":\n",
        "            self.sell()"
      ],
      "metadata": {
        "id": "Se03vLuaynXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from backtesting import Backtest\n",
        "\n",
        "for ticker in tickers_list:\n",
        "    df_test = test_data[ticker].copy()\n",
        "    signal_map = ticker_signal_map[ticker]\n",
        "\n",
        "    # Create the Backtest object\n",
        "    bt = Backtest(\n",
        "        df_test,\n",
        "        ConsistentUpDownStrategy,\n",
        "        cash=100_000,       # initial cash\n",
        "        commission=0.0,     # no commission for demonstration\n",
        "        exclusive_orders=True,\n",
        "        # We can pass signals to Strategy using strategy_kwargs\n",
        "        strategy_kwargs={\n",
        "            'custom_signal_map': signal_map\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Run the backtest\n",
        "    results = bt.run()\n",
        "\n",
        "    # Calculate net P/L in dollars\n",
        "    net_pl_dollars = results[\"Equity Final [$]\"] - results[\"Equity Initial [$]\"]\n",
        "    # backtesting.py also provides \"Return [%]\" for net percentage return\n",
        "    net_pl_percent = results[\"Return [%]\"]\n",
        "\n",
        "    # Print a summary\n",
        "    print(f\"\\n=== {ticker} Backtest Results ===\")\n",
        "    print(results)  # Detailed metrics\n",
        "    print(f\"Net P/L (USD): {net_pl_dollars:.2f}\")\n",
        "    print(f\"Net P/L (%):   {net_pl_percent:.2f}%\")\n",
        "\n",
        "    # Plot the equity curve and trades\n",
        "    # (In Colab, this should display inline. If it doesn't, you may need %matplotlib inline)\n",
        "    bt.plot()\n"
      ],
      "metadata": {
        "id": "MSK9N8yiyyjA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WKqu5vJ_o2W7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}